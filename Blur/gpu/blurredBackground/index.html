<html>

<style>
#input-area {
  display: flex;
  flex-direction: row;
  align-items: center;
  gap: 20px;
  margin: 0 0 10px 0;
}
</style>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-segmentation"></script>

<script>
let kernelSize = 10

let glProgram = null
let glScreenVertexBufferInfo = {
  buffer: null,
  size: 0,
  count: 0,
}
let glTextureBufferInfo = {
  buffer: null,
  width: 0,
  height: 0,
}
let glSegmentationBufferInfo = {
  buffer: null,
  width: 0,
  height: 0,
}

let segmenter = null
let segmentationData = null

const init = async () => {
  const segmenterConfig = {
    runtime: 'mediapipe', 
    solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation',
    modelType: 'general'
  }
  const model = bodySegmentation.SupportedModels.MediaPipeSelfieSegmentation;
  segmenter = await bodySegmentation.createSegmenter(model, segmenterConfig);

  const input = document.getElementById('img-input')
  input.addEventListener('change', (e) => {
    const file = e.target.files[0]
    const reader = new FileReader()
    reader.addEventListener('load', (e) => {
      const data = reader.result
      const img = new Image()
      img.addEventListener('load', async () => {
        await initImageData(img)
        const imgCanvas = document.getElementById('img-canvas')
        imgCanvas.width = img.width
        imgCanvas.height = img.height
        imgCanvas.style.width = img.width + 'px'
        imgCanvas.style.height = img.height + 'px'
        drawImage()
      })
      img.src = data
    })
    reader.readAsDataURL(file)
  })

  const kernelSizeInput = document.getElementById('kernel-size-input')
  kernelSizeInput.addEventListener('change', (e) => {
    kernelSize = Number(e.target.value)
    drawImage()
  })

  initWebGL()
}


const initWebGL = () => {
  const imgCanvas = document.getElementById('img-canvas')
  const gl = imgCanvas.getContext('webgl')

  const VERTEX_SHADER_SOURCE = `
    attribute vec3 aVertexPosition;
    void main(){
      gl_Position = vec4(aVertexPosition, 1.0);
    }
  `
  const vertexShader = gl.createShader(gl.VERTEX_SHADER);
  gl.shaderSource(vertexShader, VERTEX_SHADER_SOURCE);
  gl.compileShader(vertexShader);
  if (!gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS)) {
    const errorMessage = "Error compiling shader => " + gl.getShaderInfoLog(vertexShader)
    alert(errorMessage);
    console.log(errorMessage)
    gl.deleteShader(vertexShader);
    return
  }

  const FLAGMENT_SHADER_SOURCE = `
    precision mediump float;
    uniform sampler2D uTexture;
    uniform sampler2D uSegmentationData;
    uniform vec2 uImageSize;
    uniform float uKernelSize;
    uniform vec4 uFilterArea;

    void main(){
      float w = uImageSize.x;
      float h = uImageSize.y;
      float x = gl_FragCoord.x;
      float y = (h - gl_FragCoord.y);
      const float MAX_KERNEL_SIZE = 100.0;

      float fx = uFilterArea.x;
      float fy = uFilterArea.y;
      float fw = uFilterArea.z;
      float fh = uFilterArea.w;

      float segmentationValue = texture2D(uSegmentationData, vec2(x/w, 1.0-y/h)).a;
      if (segmentationValue < 1.0) {
        float blurRate = 1.0 - segmentationValue;
        float adjustedKernelSize = floor(uKernelSize * blurRate);
        float kernelHalfSize = floor(adjustedKernelSize / 2.0) + 1.0;
        vec3 color = vec3(0.0, 0.0, 0.0);
        float n = 0.0;
        for (float ky = 0.0; ky <= MAX_KERNEL_SIZE; ky += 1.0) {
          if (ky > adjustedKernelSize) {
            break;
          }
          for (float kx = 0.0; kx <= MAX_KERNEL_SIZE; kx += 1.0) {
            if (kx > adjustedKernelSize) {
              break;
            }
            float refX = x + kx - kernelHalfSize;
            float refY = y + ky - kernelHalfSize;
            color += texture2D(uTexture, vec2(refX/w, 1.0-refY/h)).xyz;
            n += 1.0;
          }
        }
        color /= n;
        gl_FragColor = vec4(color, texture2D(uTexture, vec2(x/w, 1.0-y/h)).w);
      } else {
        gl_FragColor = texture2D(uTexture, vec2(x/w, 1.0-y/h));
      }
    }
  `
  const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
  gl.shaderSource(fragmentShader, FLAGMENT_SHADER_SOURCE);
  gl.compileShader(fragmentShader);
  if (!gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS)) {
    const errorMessage = "Error compiling shader => " + gl.getShaderInfoLog(fragmentShader)
    alert(errorMessage);
    console.log(errorMessage)
    gl.deleteShader(fragmentShader);
    return
  }

  glProgram = gl.createProgram();
  gl.attachShader(glProgram, vertexShader);
  gl.attachShader(glProgram, fragmentShader);
  gl.linkProgram(glProgram);
  if (!gl.getProgramParameter(glProgram, gl.LINK_STATUS)) {
    alert("Failed to setup shaders");
  }

  const vertexPos = [
    -1.0, -1.0, 0.0,
    -1.0,  1.0, 0.0,
     1.0, -1.0, 0.0,
    -1.0,  1.0, 0.0,
     1.0,  1.0, 0.0,
     1.0, -1.0, 0.0,
  ];
  glScreenVertexBufferInfo.buffer = gl.createBuffer();
  glScreenVertexBufferInfo.size = 3;
  glScreenVertexBufferInfo.count = vertexPos.length / 3;
  gl.bindBuffer(gl.ARRAY_BUFFER, glScreenVertexBufferInfo.buffer);
  gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertexPos), gl.STATIC_DRAW);
}

const initImageData = async (image) => {
  const imgCanvas = document.getElementById('img-canvas')
  const gl = imgCanvas.getContext('webgl')

  if (glTextureBufferInfo.buffer) {
    gl.deleteTexture(glTextureBufferInfo.buffer);
    glTextureBufferInfo.buffer = null;
  }

  glTextureBufferInfo.buffer = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, glTextureBufferInfo.buffer);
  gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE); 
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
  gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image);
  glTextureBufferInfo.width = image.width
  glTextureBufferInfo.height = image.height

  const startTime = performance.now()
  const segmentationResult = await segmenter.segmentPeople(image)
  segmentationData = await segmentationResult[0].mask.toImageData();
  const endTime = performance.now()
  console.log("Segmentation : " + (endTime - startTime) + "[ms]")

  if (glSegmentationBufferInfo.buffer) {
    gl.deleteTexture(glSegmentationBufferInfo.buffer);
    glSegmentationBufferInfo.buffer = null;
  }

  glSegmentationBufferInfo.buffer = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, glSegmentationBufferInfo.buffer);
  gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE); 
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
  gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, segmentationData);
  glSegmentationBufferInfo.width = image.width
  glSegmentationBufferInfo.height = image.height
}

const drawImage = async () => {
  if (!(glTextureBufferInfo.buffer && segmentationData)) {
    return
  }

  const message = document.getElementById('message')
  message.textContent = "in progress"
  await new Promise( (res) => setTimeout(()=>{res()}, 0))
  const startTime = performance.now()

  const imgCanvas = document.getElementById('img-canvas')
  const gl = imgCanvas.getContext('webgl')
  const w = imgCanvas.width
  const h = imgCanvas.height

  gl.useProgram(glProgram);
  gl.clearColor(0.0, 0.0, 0.0, 1.0);
  gl.viewport(0, 0, w, h);

  const uImageSize = gl.getUniformLocation(glProgram, "uImageSize");
  gl.uniform2fv(uImageSize, [w, h]);

  const uKernelSize = gl.getUniformLocation(glProgram, "uKernelSize");
  gl.uniform1f(uKernelSize, kernelSize);

  const uTexture = gl.getUniformLocation(glProgram, "uTexture")
  gl.activeTexture(gl.TEXTURE0);
  gl.bindTexture(gl.TEXTURE_2D, glTextureBufferInfo.buffer);
  gl.uniform1i(uTexture, 0);

  const uSegmentationData = gl.getUniformLocation(glProgram, "uSegmentationData")
  gl.activeTexture(gl.TEXTURE1);
  gl.bindTexture(gl.TEXTURE_2D, glSegmentationBufferInfo.buffer);
  gl.uniform1i(uSegmentationData, 1);

  const aPos = gl.getAttribLocation(glProgram, "aVertexPosition");
  gl.enableVertexAttribArray(aPos);
  gl.bindBuffer(gl.ARRAY_BUFFER, glScreenVertexBufferInfo.buffer);
  gl.vertexAttribPointer(aPos, glScreenVertexBufferInfo.size, gl.FLOAT, false, 0, 0);
  gl.drawArrays(gl.TRIANGLES, 0, glScreenVertexBufferInfo.count);
  gl.disableVertexAttribArray(aPos);

  const endTime = performance.now()
  const time = Math.floor(endTime - startTime)
  const outputMessage = 'Kernel Size : ' + kernelSize + ', Time : ' + time + ' [ms]'
  console.log(outputMessage)
  message.textContent = outputMessage
}

</script>

<body onload="init()">
  <div id="main">
    <div id="input-area">
      <input type="file" id="img-input"/>
      <span>
        <span>Kernel Size</span>
        <input type="range" id="kernel-size-input" value="10" min="3" max="100"/>
      </span>
      <span id="message"></span>
    </div>
    <canvas id="img-canvas"></canvas>
  </div>
</body>

</html>
